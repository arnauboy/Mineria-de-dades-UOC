---
title: 'Mineria de dades: PAC1'
author: "Autor: Arnau Garcia Rodríguez"
date: "Octubre 2023"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 05.584-PAC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

*****
# Exemple guiat 
*****
No es tracta d'una pauta per a repetir sinó diferents exemples per donar-vos idees i inspirar-vos en la resolució.


*****
## Descripció de l'origen del conjunt de dades
*****

S'ha seleccionat un conjunt de dades del [National Highway Traffic Safety Administration](https://www.nhtsa.gov/) . El sistema d'informes d'anàlisi de mortalitat va ser creat als Estats Units per la National Highway Traffic Safety Administration per proporcionar una mesura global de la seguretat a les carreteres. (Font Wikipedia). Les dades pertany a l'any 2020. És tracta d'un conjunt de registres d'accidents que recullen dades significatives que els descriuen. Tots els accidents tenen alguna víctima mortal com a mínim. L'objectiu analític que tenim en ment és entendre que fa que un accident sigui greu i que vol dir que sigui greu. https://www.nhtsa.gov/crash-data-systems/fatality-analysis-reporting-system

## Anàlisi exploratòria

Volem fer una primera aproximació al conjunt de dades trobat i respondre a les preguntes més bàsiques. Quant registres té? Quantes variables? De quina tipologia són? Com es  distribueixen els valors de les variables? Hi ha problemes amb les dades, per exemple camps buits? Puc intuir ja el valor analític de les dades? Quines primeres conclusions puc extreure?

El primer pas per realitzar un anàlisi exploratòria és carregar el fitxer de dades.

```{r}
path = 'accident.CSV'
accidentData <- read.csv(path, row.names=NULL)
```

### Exploració del conjunt de dades

Verifiquem l'estructura del joc de dades principal. Veiem el nombre de columnes que tenim i exemples dels continguts de les files.
```{r}
structure = str(accidentData)
```

Veiem que tenim **81** variables i **35.766** registres

Revisem la descripció de les variables contingudes al fitxer i els tipus de variables es correspon al que hem carregat. Les organitzem lògicament per donar-los sentit i construïm un petit diccionari de dades utilitzant la documentació auxiliar.


+ **ST_CASE**  identificador d'accident

**FETS A ESTUDIAR**

+ **FATALS** morts 
+ **DRUNK_DR** conductors beguts
+ **VE_TOTAL** nombre de vehicles implicats en total 
+ **VE_FORMS** nombre de vehicles en moviment implicats
+ **PVH_INVL** nombre de vehicles estacionats implicats
+ **PEDS**     nombre de vianants implicats
+ **PERSONS**  nombre ocupants de vehicle implicats
+ **PERMVIT**  nombre conductors i ocupants implicats
+ **PERNOTMVIT** nombre vianants, ciclistes, a cavall... qualsevol cosa menys vehicle motoritzat

**DIMENSIÓ GEOGRÀFICA**

+ **STATE** codificació d'estat
+ **STATENAME** nom d'estat
+ **COUNTY** identificador de contat
+ **COUNTYNAME** comtat
+ **CITY** identificador de ciutat
+ **CITYNAME** ciutat
+ **NHS** 1 ha passat a autopista del NHS 0 no
+ **NHSNAME** TBD
+ **ROUTE**  identificador de ruta
+ **ROUTENAME** ruta
+ **TWAY_ID** via de transit (1982) 
+ **TWAY_ID2** via de transit (2004)
+ **RUR_URB** identificador de segment rural o urbà
+ **RUR_URBNAME** segment rural o urbà
+ **FUNC_SYS** classificació funcional segment
+ **FUNC_SYSNAME** TBD
+ **RD_OWNER** identificador propietari del segment     
+ **RD_OWNERNAME** propietari del segment 
+ **MILEPT** milla int
+ **MILEPTNAME** milla chr
+ **LATITUDE** latitud int    
+ **LATITUDENAME** latitud chr
+ **LONGITUD** longitud int
+ **LONGITUDNAME** longitud chr
+ **SP_JUR** codi jurisdicció
+ **SP_JURNAME** jurisdicció

**DIMENSIÓ TEMPORAL**

+ **DAY** dia         
+ **DAYNAME** dia repetit
+ **MONTH** mes    
+ **MONTHNAME** nom de mes
+ **YEAR** any
+ **DAY_WEEK** dia de la setmana    
+ **DAY_WEEKNAME** nom de dia de la setmana
+ **HOUR** hora
+ **HOURNAME** franja hora
+ **MINUTE** minut int
+ **MINUTENAME** minut chr

**DIMENSIÓ CONDICIONS ACCIDENT**

+ **HARM_EV** codi primer esdeveniment de l'accident que produeixi danys o lesions
+ **HARM_EVNAME** primer esdeveniment de l'accident que produeixi danys o lesions
+ **MAN_COLL** codi de posició dels vehicles 
+ **MAN_COLLNAME** posició dels vehicles
+ **RELJCT1** codi si hi ha àrea d'intercanvi
+ **RELJCT1NAME**  si hi ha àrea d'intercanvi
+ **RELJCT2** codi proximitat encreuament
+ **RELJCT2NAME** proximitat encreuament
+ **TYP_INT** codi tipus d'intersecció
+ **TYP_INTNAME** tipus d'intersecció
+ **WRK_ZONE** codi tipologia d'obres     
+ **WRK_ZONENAME** tipologia d'obres
+ **REL_ROAD**     codi ubicació vehicle a la via
+ **REL_ROADNAME** ubicació vehicle a la via
+ **LGT_COND**     codi condició lumínica
+ **LGT_CONDNAME** condició lumínica

**DIMENSIÓ METEOROLOGIA**

+ **WEATHER**     codi temps
+ **WEATHERNAME** : temps

**ALTRES**

+ **SCH_BUS** codi si vehicle escolar implicat
+ **SCH_BUSNAME** vehicle escolar implicat
+ **RAIL** codi si dins o a prop pas ferroviari
+ **RAILNAME**  si dins o a prop pas ferroviari

**DIMENSIÓ SERVEI EMERGENCIES**

+ **NOT_HOUR** hora notificació a emergències int
+ **NOT_HOURNAME** hora notificació a emergències franja 
+ **NOT_MIN** minut notificació a emergències int
+ **NOT_MINNAME** minut notificació a emergències chr
+ **ARR_HOUR** hora arribada emergències int
+ **ARR_HOURNAME** hora arribada emergències franja
+ **ARR_MIN** minut arribada emergències int
+ **ARR_MINNAME** minut arribada emergències franja 
+ **HOSP_HR** hora arribada hospital int
+ **HOSP_HRNAME** hora arribada hospital franja
+ **HOSP_MN** minut arribada hospital int
+ **HOSP_MNNAME** : minut arribada hospital franja

## Preprocessament i gestió de característiques

### Neteja

El següent pas serà la neteja de dades, mirant si hi ha valors buits o nulls. 

```{r echo=TRUE, message=FALSE, warning=FALSE}
print('NA')
colSums(is.na(accidentData))
print('Blancs')
colSums(accidentData=="")
```

Veiem que no hi ha valors nuls a les dades. També verifiquem camps omplerts de espais en blanc. En aquest cas sí trobem el camp TWAY_ID2 amb 26.997 valors en blanc. Valorem no fer cap acció d'eliminar registres ja que aquest camp no l'utilitzarem.


Anem a crear histogrames i descriure els valors per veure les dades en general d'aquests atributs per fer una primera aproximació al contingut de les dades:

```{r echo=TRUE, message=FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if(!require('Rmisc')) install.packages('Rmisc'); library('Rmisc')
if(!require('dplyr')) install.packages('dplyr'); library('dplyr')
if(!require('xfun')) install.packages('xfun'); library('xfun')

summary(accidentData[c("FATALS","DRUNK_DR")])
#Crearem primer una llista per mostrar desprès les gràfiques en un sol grid 
#Crearem una llista per mostrar els atributs que interessen.
histList<- list()

n = c("FATALS","DRUNK_DR")
accidentDataAux= accidentData %>% select(all_of(n))
for(i in 1:ncol(accidentDataAux)){
  col <- names(accidentDataAux)[i]
  ggp <- ggplot(accidentDataAux, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "cornflowerblue", color = "black",ggtittle = "Comptador d'ocurrències per variable") 
      histList[[i]] <- ggp  # afegim cada plot a la llista buida
}
 multiplot(plotlist = histList, cols = 1)

```


Observacions: 

Nombre de morts: Tots els accidents recollits en aquestes dades reporten una mort com a mínim. Sent l'accident més greu amb vuit víctimes i veiem que la distribució s'acumula de forma molt evident en una mort per accident.

Conductors beguts involucrats a l'accident: Analitzarem amb més detall aquesta dada més endavant per derivar una nova dada: Accidents on l'alcohol està present o no. D'entrada la mitjana és de 0.26% d'accidents on intervé un conductor begut. La franja va d'un conductor a quatre com a màxim que apareixen en un accident amb víctimes mortals.

```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(accidentData[c("VE_TOTAL","VE_FORMS","PVH_INVL")])
#Crearem una llista per mostrar els atributs que interessen.
histList<- list()
n = c("VE_TOTAL","VE_FORMS","PVH_INVL")
accidentDataAux= accidentData %>% select(all_of(n))
for(i in 1:ncol(accidentDataAux)){
  col <- names(accidentDataAux)[i]
  ggp <- ggplot(accidentDataAux, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "cornflowerblue", color = "black") 
      histList[[i]] <- ggp  # afegim cada plot a la llista buida
}
 multiplot(plotlist = histList, cols = 1)

```

Observacions pel que fa als vehicles implicats. 

Nombre de vehicles implicats (VE_TOTAL) en total està a la franja de 1 fins 59 sent el valor màxim i una mitjana de 1,5. 
Nombre de vehicles en moviment implicats (VE_FORMS), el valor més habitual és 1 amb un valor màxim també de 59. Preveiem que hi ha un valor extrem que caldrà tractar per poder treure més informació d'aquesta variable.
Nombre de vehicles estacionats implicats (PHL_INVL): Pel que fa aquesta variable l'habitual és que no hi hagi vehicles estacionats pels incidents recollits en aquestes dades. Amb tot apareixen casos aïllats on fins i tot hi havia 10 cotxes estacionats.


```{r echo=TRUE, message=FALSE, warning=FALSE}
summary(accidentData[c("PEDS","PERSONS","PERMVIT","PERNOTMVIT")])
#Crearem una llista per mostrar els atributs que interessen.
histList<- list()
n = c("PEDS","PERSONS","PERMVIT","PERNOTMVIT")
accidentDataAux= accidentData %>% select(all_of(n))
for(i in 1:ncol(accidentDataAux)){
  col <- names(accidentDataAux)[i]
  ggp <- ggplot(accidentDataAux, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "cornflowerblue", color = "black") 
      histList[[i]] <- ggp  # afegim cada plot a la llista buida
}
 multiplot(plotlist = histList, cols = 1)
```

Observacions pel que fa a les persones implicades en un accident.

El nombre de vianant implicats (PEDS) és molt baix sent coherent amb el tipus de via que s'estudia i on no és habitual que hi hagi gent caminant. Amb tot el valor com a mitjana de 0,22 i màxim de 8 obliga a investigar més aquesta dada.
(PERSONS) El nombre d'ocupants de vehicle implicats es situa com a mitjana en 2,1  (PERMVIT) El nombre conductors i ocupants de vehicles en circulació implicats amb valor de mitjana de 2,1. Aquestes dues variables recullen la mateixa informació però la quantifiquen de diferent manera. L'accident amb el major nombre d'ocupants és de 61 persones.  
Pel que nombre vianant, ciclistes, fins i tot persones en vehicles aparcats... qualsevol cosa menys vehicle circulant (PERNOTMVIT) veiem que augmenta una mica la mitjana respecte a vianant ja que entenen que s'inclouen més casos.

Anem a aprofundir una mica en el tema de la relació de l'alcohol en els conductors i el nombre d'accidents.

```{r}
accidentData$alcohol <- ifelse(accidentData$DRUNK_DR %in% c(0), 0, 1)
counts <- table(accidentData$alcohol)
barplot(prop.table(counts),col=c("green","red"), main="Accidents amb conductor begut", legend.text=c("No Alcohol","Sí Alcohol"),xlab ="Presencia Alcohol", ylab = "Percentatge",ylim=c(0,0.8) )
```

Veiem que percentualment a la gran majoria d'accidents, al voltant del 75% no hi ha presència d'alcohol en el conductor. El conductors que donen positiu estan al voltant d'un 22%. Hem cercat contrastar la dada amb altres països i estarien en un valor central on els valors extrems màxim per país superen el 50% i els mínims estan sobre el 10%

Observem ara com es distribueixen les morts per accident.
```{r}
df1 <- accidentData %>%
  group_by(accidentData$FATALS) %>%
  dplyr::summarise(counts = n())
df1

counts <- table(accidentData$FATALS)
barplot(prop.table(counts),col=("red"),ylim=c(0,0.99),main="Distribució de la mortalitat als accidents",xlab ="Nombre de morts", ylab = "Percentatge")
```

Veiem que la majoria d'accidents tenen com a mínim un mort. Anem ara estudiar relacionat mortalitat alcohol.
```{r}
counts <- table(accidentData$alcohol, accidentData$FATALS)
colors <- c("green", "red")
barplot(prop.table(counts), beside = TRUE, col = colors, 
        ylim = c(0, 1), axes = TRUE,
        xlab = "Nombre de morts",
        ylab = "Percentatge",
        main = "Accidents per morts i conductors positius en alcohol",
        legend = c("No Alcohol", "Alcohol"), 
        fill = colors)
```

```{r}
counts <- table(accidentData$FATALS, accidentData$alcohol)
barplot(prop.table(counts), main="Accidents per conductors positius en alcohol i nombre de morts",
  xlab="0 No alcohol 1 Alcohol", col=rainbow(8), ylab="Percentantge",                             
  legend = rownames(counts), beside=TRUE,ylim=c(0,0.8))
```


Provarem ara si hi ha relació entre l'estat on ha passat l'accident i el nombre de conductors beguts. Fitrem els cinc estats on hi ha més accidents.

```{r echo=TRUE, message=FALSE, warning=FALSE}
accidentDataST5=subset(accidentData, accidentData$STATENAME == "California" | accidentData$STATENAME == "Texas" | accidentData$STATENAME == "Florida" | accidentData$STATENAME == "Georgia" | accidentData$STATENAME == "North Carolina")
files=dim(accidentDataST5)[1]
ggplot(data=accidentDataST5[1:files,],aes(x=DRUNK_DR,fill=STATENAME))+geom_bar()+ggtitle("Relació entre les variables conductor begut i Estat")+labs(x="Nombre de conductors beguts implicats")
```

Com a reflexió aquest gràfic té que passar pel filtre de percentuar el nombre d'accidents per estat i la població de l'estat per no treure conclusions precipitades.

Vegem ara com en un mateix gràfic de freqüències podem treballar amb 3 variables: FATALS, STATENAME i WEATHERNAME.


```{r echo=TRUE, message=FALSE, warning=FALSE}
ggplot(data = accidentDataST5[1:files,],aes(x=FATALS,fill=STATENAME))+geom_bar(position="fill")+facet_wrap(~WEATHERNAME)+ggtitle("Nombre de morts en accident per Estat i clima")+labs(x="Nombre de morts") 
```

Aquesta gràfica està bé com a mecànica de construcció però els resultats els posem en dubte. Està bé com a pas inicial però cal aprofundir molt més. 

Anem a cercar les correlacions en funció de les morts i unes variables triades que creiem poden ajudar a explicar l'augment de morts per accident:

**DRUNK_DR** conductors beguts
**VE_TOTAL** nombre vehicles implicats en total 
**VE_FORMS** nombre vehicles en moviment implicats
**PVH_INVL** nombre vehicles estacionats implicats
**PEDS**     nombre vianants implicats
**PERSONS**  nombre ocupants de vehicle implicats
**PERMVIT**  nombre conductors i ocupants implicats
**PERNOTMVIT** nombre vianants, ciclistes... qualsevol cosa menys vehicle motoritzat



```{r echo=TRUE, message=FALSE, warning=FALSE}
# Utilitzem aquesta llibreria per fer servir la funcio multiplot()
if(!require('Rmisc')) install.packages('Rmisc'); library('Rmisc')
#Crearem primer una llista per mostrar les gràfiques de correlacions
#Crearem una llista per mostrar els atributs que interessen.


n = c("DRUNK_DR","VE_TOTAL","VE_FORMS","PVH_INVL","PEDS","PERSONS","PERMVIT","PERNOTMVIT") 
accidentDataAux= accidentData %>% select(all_of(n))
histList2<- vector('list', ncol(accidentDataAux))
for(i in seq_along(accidentDataAux)){
  message(i)
histList2[[i]]<-local({
  i<-i
  col <-log(accidentDataAux[[i]])
  ggp<- ggplot(data = accidentDataAux, aes(x = accidentData$FATALS, y=col)) + 
    geom_point(color = "gray30") + geom_smooth(method = lm,color = "firebrick") + 
    theme_bw() + xlab("Morts") + ylab(names(accidentDataAux)[i])
  })

}
multiplot(plotlist = histList2, cols = 3)
```

Podem veure que:

+ De forma general qualsevol augment en les variables triades implica un augment de les morts al accident.

+ El factor que fa augmentar més el nombre de víctimes son les variables relacionades amb els vianants i passatgers dels cotxes involucrats a l'accident.

Utilitzem les columnes que ens interessa per fer la matriu i la visualitzarem utilitzant la funció corrplot.
```{r echo=TRUE, message=FALSE, warning=FALSE}
# https://cran.r-project.org/web/packages/corrplot/vignettes/corrplot-intro.html
if(!require("corrplot")) install.packages("corrplot"); library("corrplot")
n = c("FATALS","DRUNK_DR","VE_TOTAL","VE_FORMS","PVH_INVL","PEDS","PERSONS","PERMVIT","PERNOTMVIT")
factors= accidentData %>% select(all_of(n))
res<-cor(factors)
corrplot(res,method="color",tl.col="black", tl.srt=30, order = "AOE", 
   number.cex=0.75,sig.level = 0.01, addCoef.col = "black")
```

No veiem que hi hagi una correlació negativa significativa entre cap variable i sí una molt bona correlació ja previsible entre els vianants implicats i persones involucrades a l'accident que no van en cotxe. (PEDS i PERNOTMVIT) El mateix podem observar pel que fa al nombre de conductors i ocupants implicats (PERMVIT) i el nombre de vehicles implicats en moviment (VE_FORMS) o el total de vehicles (VE_TOTAL). 

Anem a provar si hi ha una correlació entre l'hora del accident  i el nombre de morts.

```{R}
if (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')
cor.test(x = accidentData$PERSONS, y = accidentData$FATALS, method = "kendall")
ggplot(data = accidentData, aes(x = PERSONS, y = log(FATALS))) + geom_point(color = "gray30") + geom_smooth(color = "firebrick") + theme_bw() +ggtitle("Correlació entre persones implicades a l'accident i nombre de morts")
```

De l'observació d'aquest gràfic podem concloure que efectivament el nombre de morts augmenta en funció de les persones implicades en un accident però que la correlació no és tan elevada ni continua com es podia preveure.

## Construcció de conjunt de dades final  

Si dues variables estan tan altament correlacionades que òbviament impartiran gairebé exactament la mateixa informació en un  model de regressió per exemple. Però, en incloure totes dues, en realitat estem debilitant el model. No estem afegint informació incremental. En lloc d'això, estem fent un model sorollós. No és una bona cosa.

Com hem vist abans tenim una correlació molt gran entre PEDS i PERNOTMVIT, per tant podríem eliminar la columna de vianants (PEDS) i deixar el total de vianants i altres reflectit a PERNOTMVIT.
```{r echo=TRUE, message=FALSE, warning=FALSE}
# accidentData$PEDS<- NULL
str(accidentData)

```

### Codificació

Seguidament anem a assignar un 1 per accidents que es produeixen de matinada (01h a 06h a l'hivern) i un 0 per a la resta de franja horària, es a dir, anem a categoritzar la variable HOUR i així tindrem una variable numèrica que ens permetrà treballar millor en el futur, l'anomenarem matinada. Després l'utilitzarem per veure com es distribueixen els accidents en les dues franges horàries. Hem de tenir en compte que la hora inclou el codi 99 què vol dir que l'hora no està informada. Mirarem de filtrar els registres amb aquest valor per excloure'ls. 
```{r}

accidentDataAux=subset(accidentData, accidentData$HOUR <= 24)

accidentData$matinada <- NA
accidentData$matinada[accidentDataAux$HOUR >=1 & accidentDataAux$HOUR <= 6] <- 1
accidentData$matinada[accidentDataAux$HOUR ==0 | accidentDataAux$HOUR >6 ] <- 0

counts <- table(accidentData$matinada)
barplot(prop.table(counts),col=c("green","red"),legend.text=c("Resta del dia","Matinada"),ylim=c(0,1), main="Distribució d'accidents la matinada i resta del dia",xlab="0 Resta del dia 1 Matinada",ylab="Percentatge" )

```

### Discretització

Ara afegirem un camp nou a les dades. Aquest camps contindrà el valor de l'hora de l'accident discretitzada amb un mètode simple d'intervals d'igual amplitud.

```{r echo=TRUE, message=FALSE, warning=FALSE}

summary(accidentDataAux[,"HOUR"])
```

Discretitzem amb intervals. Els criteris de tall horaris estan agafats de la Web del Parlament de Catalunya.

```{r}
accidentDataAux["segment_horari"] <- cut(accidentDataAux$HOUR, breaks = c(0,4,11,14,18,22), labels = c("Matinada", "Matí", "Migdia", "Vespre","Nit"))
```

Observem les dades discretitzades i construïm un gràfic per analitzar com s'agrupen els accidents. 

```{r}
head(accidentDataAux$segment_horari)
```
```{r}
plot(accidentDataAux$segment_horari,main="Nombre d'accidents per segment horari",xlab="Segment horari", ylab="Quantitat",col = "ivory")
```

Ara anem a discretitzar la variable que conté el nombre de vehicles implicats en un accident (VE_TOTALS) ja que era una de les que las distancies entre els seus valors era molt gran: 


```

### Normalització


Ara normalitzarem el nombre de morts pel màxim afegint un nou valor a les dades que contindrà el valor. 

```{r}
accidentData$FATALS_NM<- (accidentData$FATALS/max(accidentData[,"FATALS"]))
head(accidentData$FATALS_NM)

```
Suposem que ens cal normalitzar per la diferencia per ubicar entre 0 i 1 la variable del nombre de morts de l'accident donat que l'algorisme de mineria que utilitzarem així ho requereix. Observem la distribució de la variable original i les  generades.
```{r}

accidentData$FATALS_ND = (accidentData$FATALS-min(accidentData$FATALS))/(max(accidentData$FATALS)-min(accidentData$FATALS))

max(accidentData$FATALS)
min(accidentData$FATALS)
hist(accidentData$FATALS,xlab="Morts", col="ivory",ylab="Quantitat", main="Nombre de morts en accident")
hist(accidentData$FATALS_NM,xlab="Morts",ylab="Quantitat",col="ivory", main="Morts normalitzat pel màxim")
hist(accidentData$FATALS_ND,xlab="Morts",ylab="Quantitat", col="ivory", main="Morts normalitzat per la diferència")
```

A continuació anem a normalitzar les altres columnes per assegurar-nos que cada variable contribueix per igual al nostre anàlisis. 
```{r}
# Definim la funció de normalització
 nor <-function(x) { (x -min(x))/(max(x)-min(x))}
# Guardem un nou dataset normalitzat

accidentData$type<- NULL
n = c("FATALS","DRUNK_DR","VE_TOTAL","VE_FORMS","PVH_INVL","PEDS","PERSONS","PERMVIT","PERNOTMVIT")
accidentData<- accidentData %>% select(all_of(n))
accidentData_nor <- as.data.frame(lapply(accidentData, nor))

 head(accidentData_nor)
```

## Procés de PCA 

Tant l’ **anàlisi de components principals, principal component analysis (PCA) en anglès, com la descomposició de valors singulars, singular value decomposition (SVD) **en anglès, són tècniques que ens permeten treballar amb noves característiques anomenades components, que certament són independents entre si.
En realitat, aquestes dues tècniques ens permeten representar el joc de dades en un nou sistema de coordenades que anomenem components principals.
Aquest sistema està més ben adaptat a la distribució del joc de dades, de manera que recull millor la seva variabilitat.

Apliquem l'anàlisi de components principals al row data set per això comencem executant la funció **prcomp()**.
```{r}
pca.acc <- prcomp(accidentData_nor)
summary(pca.acc)
```

Com es pot observar la funció summary, ens torna la proporció de variància aplicada al conjunt total de cada atribut. Gràcies a això, l'atribut 1 explica el 0.452 de variabilitat del total de dades; en canvi, l'atribut 7 explica només el 0.00381.

A continuació es mostra un histograma per veure el pes de cada atribut sobre el conjunt total de dades, 
```{r}
if (!require('factoextra')) install.packages('factoextra'); library('factoextra')
#Els valors propis corresponen a la quantitat de variació explicada per cada component principal (PC).
ev= get_eig(pca.acc)
ev
fviz_eig(pca.acc)
```

En aquest exercici es va decidir utilitzar el mètode de Kàiser per decidir quina de les variables obtingudes seran escollides. Aquest criteri mantindrà totes aquelles variables la variància de les quals sigui superior a 1. 
```{r}
# Calculem la variància dels components principals a partir de la desviació estàndard

var_acc <- pca.acc$sdev^2

var_acc
```

Amb els resultats obtinguts és molt complicat decidir quines són les components principals components a escollir. **Aquest fet podria estar causat per no haver escalat les dades prèviament.** Per tant, el següent pas és escalar les dades i tornar a calcular la variància per veure quines dades selecciones
```{r}
# Escalem les dades
acc_scale <- scale(accidentData_nor)
# Calculem les components principals
pca.acc_scale <- prcomp(acc_scale)
# Mostramos la varianza de dichas variables:
var_acc_scale <- pca.acc_scale$sdev^2
head(var_acc_scale)
```

Després d'analitzar la variància i aplicant el criteri de Kàiser ens quedarem amb les components principals 1,2,3 i 4 que són les superiors a 1. Aquest criteri té el problema de sobreestimar el nombre de factors, però malgrat això és el que aplicarem per analitzar els resultats.

Mostrem l'histograma de percentatge de variància explicat amb les dades escalades:
```{r}
fviz_eig(pca.acc_scale)
ev = get_eig(pca.acc_scale)
ev
```

Els valors propis es poden utilitzar per determinar el nombre de components principals a retenir després de la PCA (Kaiser 1961):

+ Un valor propi > 1 indica que els PCs representen més variància de la que representa una de les variables originals de les dades estandarditzades. Això s'utilitza habitualment com a punt de tall per al qual es conserven els PCs. Això només és cert quan les dades estan estandarditzades.

+ També podem limitar el nombre de components a aquest nombre que representa una determinada fracció de la variància total. Per exemple, si estem satisfets amb el 80% de la variància total explicada, fem servir el nombre de components per aconseguir-ho que són les 4 components principals vists abans.

Continuem amb l'anàlisi dels components principals. Després d'aplicar el mètode Kàiser s'han seleccionat els 4 components principals.

```{r}
var <- get_pca_var(pca.acc_scale)
var
```

Els components de get_pca_var() es poden utilitzar en el diagrama de variables de la següent manera:

+ **var$coord**: coordenades de variables per crear un diagrama de dispersió.
+ **var$cos2**: representa la qualitat de representació de les variables al mapa de factors. Es calcula com les coordenades al quadrat: var.cos2 = var.coord * var.coord.
+ **var$contrib**: conté les contribucions (en percentatge) de les variables als components principals. La contribució d'una variable (var) a un determinat component principal és (en percentatge): (var.cos2 * 100) / (cos2 total del component).

```{r}
#Utilitzem els 4 components principals trobats abans
head(var$coord[,1:4],11)
```

### Qualitat de representació
La qualitat de representació de les variables en el mapa de factors s'anomena cos2 (cosinus quadrat, coordenades quadrades). Podem accedir al cos2 de la següent manera:

```{r}
head(var$cos2[,1:4],11)
```
```{r}
corrplot(var$cos2[,1:4], is.corr=FALSE)
```

També és possible crear un diagrama de barres de variables cos2 mitjançant la funció fviz_cos2():
```{r}
fviz_cos2(pca.acc_scale, choice = "var", axes = 1:2)
```

+ Un cos2 elevat indica una bona representació de la variable en el component principal. En aquest cas, la variable es col·loca prop de la circumferència del cercle de correlació.

+ Un cos2 baix indica que la variable no està perfectament representada pels PC. En aquest cas, la variable està a prop del centre del cercle.

Per a una variable donada, la suma del cos2 de tots els components principals és igual a un.

Si una variable està perfectament representada per només dos components principals (Dim.1 i Dim.2), la suma del cos2 en aquests dos PCs és igual a un. En aquest cas les variables es col·locaran en el cercle de correlacions.

Per a algunes de les variables, poden ser necessaris més de 2 components per representar perfectament les dades. En aquest cas les variables es situen dins del cercle de correlacions.

En resum:

+ Els valors de cos2 s'utilitzen per estimar la qualitat de la representació
+ Com més propera estigui una variable al cercle de correlacions, millor serà la seva representació al mapa de factors (i més important és interpretar aquests components)
+ Les variables que estan properes al centre de la trama són menys importants per als primers components.
```{r}
fviz_pca_var(pca.acc_scale,
             col.var = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     
             )
```

###  Contribució

Les contribucions de les variables en la comptabilització de la variabilitat d'un determinat component principal s'expressen en percentatge.

Les variables que estan correlacionades amb PC1 (és a dir, Dim.1) i PC2 (és a dir, Dim.2) són les més importants per explicar la variabilitat en el conjunt de dades.

Les variables que no estan correlacionades amb cap PC o amb les darreres dimensions són variables amb una contribució baixa i es poden eliminar per simplificar l'anàlisi global.

La contribució de les variables es pot extreure de la següent manera:
```{r}
head(var$contrib[,1:4],11)
```

Quan més gran sigui el valor de la contribució, més aportació de la variable hi haurà al component.

```{r}
corrplot(var$contrib[,1:4], is.corr=FALSE)
``` 

Les variables més importants (que més contribueixen) es poden ressaltar a la gràfica de correlació de la següent manera:
```{r}
fviz_pca_var(pca.acc_scale, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
             )
``` 

Les variables correlacionades positives apunten al mateix costat de la trama. Les variables correlacionades negatives apunten a costats oposats del gràfic. Per exemple, veiem que les persones involucrades en un accident (PVH_INVL) i conductor begut (DRUNK_DR) apunten direccions oposades per tan no estan gens correlaciones, a més ho hem vist abans ja que tenen un coeficient de correlació de -0.01.

S' observa que la variable que més aporta a les components principals són **PEDS i PERNOTMVIT per un costat  i VE_TOTAL, VE_FORMS, PERSONS i PERMVIT**. Això és degut al fet que estan correlacionades. En concret pel diagrama de correlació d' abans que PEDS esta molt bé correlacionada amb PERNOTMVIT. D' altra banda VE_TOTAL, VE_FORMS, PERSONS i PERMVIT estan també força correlacionades. La correlació de FATALS amb aquest grup de variables no és elevada però apunta en la mateixa direcció.

Podrien ara refer els components excloent les variables que no aporten informació. Un cop refet aquestes noves variables substitueixen a les originals que les formen i es podrien utilitzar per exemple com un indicador de gravetat d'accident ja que inclou vehicle en moviment, aturat, vianants, conductors i d'altres implicats en una sola variable. 

## Interpretació dels resultats

Las dades estudiades contemplen accidents de tràfic amb víctimes a les xarxes d’autopistes als EUUU a llarg del 2020. Tots els registres tenen un identificador únic d’accident i una sèrie de fets principals com nombre de morts, nombre de conductors beguts, vehicles i persones ¡ persones implicades. Hem d’afegir altres variables que els caracteritzen agrupades de ubicació geogràfica, temporal, condicions específiques de l’accident, meteorològiques, la intervenció del serveis d’emergències  i d’altres factors.

Revisades les dades semblen ben informades  sense  Les dades estan força netes i ben documentades. No plantegen greus problemes de camps amb valors nuls o buits i tenen força potencial per generar nous indicadors a partir de les dades.

Podem afirmar que al llarg del 2020 a les autopistes d'EEUU van succeir 35.766 accidents on van perdre la vida 38.824 persones. Pretenien extreure relacions entre la presencia d'alcohol en els conductors i el nombre d'accidents però les conclusions no son clares. Les relacions més obvies però comprovades són el increment de morts en funció de l’increment del nombre de vehicles, passatgers i vianants implicats.  

Caldria aprofundir molt més. Sí que podem perfilar com són els accidents típics pel que fa al nombre de vehicles i persones, conductors o vianants implicats.

El més habitual és un mort per accident incrementant-se aquest valor en funció de les variables relacionades. Els conductors beguts apareixen en un de cada quatre accidents mortals aproximadament.  Els vehicles implicats en els accident són típicament un en aquests tipus d’accident podent-se incrementar a dos en els casos més típics.  El nombre de vianants implicats és relativament baix donat el tipus de via que estem estudiant.

Pel que fa al consum d’alcohol amb el grau de profunditat estudiat no s’observa un estat on la proporcionalitats del nombre de conductor amb presència d’alcohol  sigui superior.

Estudiant el nombre de morts en accident en relació a l’Estat on ha succeït i la condició climàtica veiem necessari aprofundir amb tècniques per exemple d’agregació ver veure com s’agrupen i poder obtenir un perfil.  

S’ha estudiat la franja horària de la matinada per veure si acumulava un major nombre d’accidents no sent així. Sembla que el nombre d’accidents manté també proporcionalitat. S’ha estudiant el nombre d’accidents per segment horari amb una discretització fixada en interval arbitraris. La major presencia d’accidents en horari de matí i vespre (anar i tornar a la feina) fa pensar en que queda pendent estudiar donat el tipus de via la distribució horària dels accidents dilluns a divendres respecte als caps de setmana i festius per veure si hi ha hores on s’acumulen més accidents mortals. 

Finalment amb la tècnica dels components principals hem generat una nova variable que combina d’altres variables amb una correlació inicial que es podria considerar com índex de gravetat de l’accident.



*****
# Exercici 1
*****


Proposa un projecte complet de mineria de dades. L'organització de la resposta ha de coincidir en les fases típiques del cicle de vida d'un projecte de mineria de dades. **No cal fer les tasques de la fase**. Per a cada fase indica quin és el objectiu de la fase i el producte que s'obtindrà. Utilitza exemples de quines i com podrien ser les tasques. Si hi ha alguna característica que fa diferent el cicle de vida d'un projecte de mineria respecte a d'altres projectes indica-ho.


> Escriu aquí la resposta a la pregunta


El projecte de mineria de dades que tractarem en aquest apartat consisteix en **l'estudi d'accidents laborals** per a poder aplicar mesures preventives. 

## Definició de la tasca de mineria de dades

A la primera fase, la tasca principal serà **definir quin es l'objectiu del nostre projecte de mineria de dades**. Generalment, s'adequa a un dels següents:

- Trobar similituds i agrupar objectes semblants

- Classificar grups tenint-los prèviaments definits

- Predir allò que ens interessi

- Adquirir coneixement descriptiu, és a dir, trobar relacions significatievs entre variables 

- Otenir models que expliquin per què s'ha dut a terme un comportament determinat.

En aquesta fase també caldrà decidir quin model s'utilitzarà i quins mètodes i eines s'empraran per construir-lo.

Un cop acabada aquesta primera etapa, cal trobar les dades. Aquestes fonts de dades solen obtenir-se de bases de dades de diferents departaments i de bases de dades transaccional, que guarden un històric d'operacios.

## Preparació de les dades

Un cop definida la tasca de mineria, cal **preparar les dades** per a poder-les fer servir per obtenir el model desitjat. A grans trets, l'objectiu és que les dades siguin de prou qualitat, necessàries i que estiguin en el format adequat. Les tècniques que ens permetran assegurar aquests aspectes son:

- Neteja: Consisteix en borrar les dades errònies i redundants.
- Transformació: Molts cops trobarem que les dades no estan en el format adequat per a poder utilitzar-les per a crear el model que desitjem.
- Reducció: A partir de certes quantitats de dades els algorismes comencen a reduïr la seva eficiència. L'ideal es treballar amb la mínima quantitat de dades que ens permeti obtenir els mateixos resultats.

## Mineria de dades

En començar aquesta tercera fase, es tindrà decit el model i les dades seran de qualitat. Per tant, caldrà **decidir els mètodes de construcció del model**. Això vol dir trobar el model que millor s'adeqüi a les característiques de les nostres dades, és a dir, començar un procés de cerca.

Al final d'aquestra fase tindrem un model que representa un coneixement sobre el domini estudiat. En aquest apunt, cal avaluar-lo mitjançant conjunts de dades que provenen del mateix conjunt incial. Un s'utilitzarà per avaluar-lo, l'altre per validar-l i l'altre per construir-lo. Finalment, un cop avaluat i es tingui la certesa de que el model compleix el nivell de qualitat requerit, cal interpretar-lo i extreure la informació al coneixement.

## Integració

L'última fase consisteix en integrar en els processos del sistema d'informació els resultats del model trobat. Aquest model caldrà traduirlo al llenguatge de programació corresponent.



*****
# Exercici 2
*****
A partir del joc de dades utilitzat a l'exemple de la PAC, realitza les tasques prèvies a la generació d’un model de mineria de dades explicades en els mòduls  "El procés de mineria de dades" i "Preprocessat de les dades i gestió de característiques". Pots utilitzar de referència l'exemple però procura canviar l'enfocament i analitzar les dades en funció de les diferent dimensions que presenten les dades. Opcionalment i valorable es poden afegir a l'estudi de dades d'altres anys per a realitzar comparacions temporals (https://www.nhtsa.gov/file-downloads?p=nhtsa/downloads/FARS/) o afegir altres fets a estudiar relacionats, per exemple el consum de drogues en els accidents (https://static.nhtsa.gov/nhtsa/downloads/FARS/2020/National/FARS2020NationalCSV.zip)

```{r echo=TRUE, message=FALSE, warning=FALSE}
# Carreguem el joc de dades

# Redacta aquí el codi R per a l'estudi del joc de dades
```
> Escriu aquí la resposta a la pregunta



