---
title: 'Mineria de dades: PAC1'
author: "Autor: Arnau Garcia Rodríguez"
date: "Octubre 2023"
output:
  html_document:
    highlight: default
    number_sections: yes
    theme: cosmo
    toc: yes
    toc_depth: 2
    includes:
      in_header: 05.584-PAC-header.html
  pdf_document:
    highlight: zenburn
    toc: yes
  word_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```


*****
# Exercici 1
*****

El projecte de mineria de dades que tractarem en aquest apartat consisteix en **l'estudi de dades sobre accidents laborals a una empresa per a poder aplicar mesures preventives.**

## Definició de la tasca de mineria de dades

A la primera fase, la tasca principal serà **definir quin es l'objectiu del nostre projecte de mineria de dades**. Generalment, s'adequa a un dels següents:

- Trobar similituds i agrupar objectes semblants

- Classificar grups tenint-los prèviaments definits

- Predir allò que ens interessi

- Adquirir coneixement descriptiu, és a dir, trobar relacions significatievs entre variables 

- Otenir models que expliquin per què s'ha dut a terme un comportament determinat.

En aquesta fase també caldrà decidir quin model s'utilitzarà i quins mètodes i eines s'empraran per construir-lo.

Un cop acabada aquesta primera etapa, cal trobar les dades. Aquestes fonts de dades solen obtenir-se de bases de dades de diferents departaments i de bases de dades transaccional, que guarden un històric d'operacios.

## Preparació de les dades

Un cop definida la tasca de mineria, cal **preparar les dades** per a poder-les fer servir per obtenir el model desitjat. A grans trets, l'objectiu és que les dades siguin de prou qualitat, necessàries i que estiguin en el format adequat. Les tècniques que ens permetran assegurar aquests aspectes son:

- Neteja: Consisteix en borrar les dades errònies i redundants.
- Transformació: Molts cops trobarem que les dades no estan en el format adequat per a poder utilitzar-les per a crear el model que desitjem.
- Reducció: A partir de certes quantitats de dades els algorismes comencen a reduïr la seva eficiència. L'ideal es treballar amb la mínima quantitat de dades que ens permeti obtenir els mateixos resultats.

## Mineria de dades

En començar aquesta tercera fase, es tindrà decidit el model i les dades seran de qualitat. Per tant, caldrà **decidir els mètodes de construcció del model**. Això vol dir trobar el model que millor s'adeqüi a les característiques de les nostres dades, és a dir, començar un procés de cerca.

Al final d'aquestra fase tindrem un model que representa un coneixement sobre el domini estudiat. En aquest apunt, cal avaluar-lo mitjançant conjunts de dades que provenen del mateix conjunt incial. Un s'utilitzarà per avaluar-lo, l'altre per validar-l i l'altre per construir-lo. Finalment, un cop avaluat i es tingui la certesa de que el model compleix el nivell de qualitat requerit, cal interpretar-lo i extreure la informació al coneixement.

## Integració

L'última fase consisteix en integrar en els processos del sistema d'informació els resultats del model trobat. Aquest model caldrà traduirlo al llenguatge de programació corresponent.


*****
# Exercici 2
*****
> Escriu aquí la resposta a la pregunta

A partir de dades extretes d'un sistema d'anàlisi de mortalitat de l'any 2020 i facilitades pel National Highway Traffic Safety Administration, amb informació sobre la seguretat a les carreteres, passarem per cadascuna de les etapes i tasques prèvies a la generació d'un model de mineria de dades. Procurarem fer èmfasi en la gestió de característiques i aprofundir en la relació entre els diversos atributs. L'objectiu és extreure coneixement d'aquestes dades i saber quines condicions fan que un accident sigui greu. Seguirem l'exemple de l'enunciat, però procurarem tractar dimensions diverses i extreure coneixement diferent.

## Exploració de les dades

El primer pas és carregar les dades, i a continuació, fer una primera exploració de la dimensionalitat i el tipuis d'informació que ens facilita.

```{r}
path = 'accident.CSV'
accidentData <- read.csv(path, row.names=NULL)
```

```{r}
structure = str(accidentData)
```

Veiem com a la primera fila del resultat ens indica que disposem de **35766 tuples** i **81 atributs** o característiques.

Utilitzant la documentació auxiliar que tenim hem construÏt un diccionari d'un subconjunt de les característiques disponibles que tenim de les dades, que seran les que estudiarem.

+ **ST_CASE**  identificador d'accident

**SUBCONJUNT DE DIMENSIONS**

+ **FATALS** nombre de morts 
+ **DRUNK_DR** nombre de conductors beguts
+ **VE_TOTAL** nombre de vehicles implicats en total 
+ **VE_FORMS** nombre de vehicles en moviment implicats
+ **PEDS**     nombre de vianants implicats
+ **PERSONS**  nombre ocupants de vehicle implicats
+ **PERMVIT**  nombre conductors i ocupants implicats
+ **PERNOTMVIT** nombre de persones que no anaven amb vehicle motoritzat
+ **PVH_INVL** nombre de vehicles estacionats implicats
+ **STATE** codificació de l'estat
+ **STATENAME** estat
+ **MONTH** número de mes de l'any   
+ **HOUR** hora
+ **HOURNAME** franja horaria
+ **WEATHER** codi condicions meteorològiques


## Preparació de les dades

En aquest apartat, preparearem les dades per a que se'ls puguin aplicar les eines que construiran el model. Les dades resultants d'aquesta etapa hauran de ser de prou qualitat, necessàries i s'hauran de trobar en un format adequat.

### Neteja

En aquest apartat tractarem les dades nules o absents.

Primer buscarem si tenim valors nuls al nostre conjunt de dades.

```{r echo=TRUE, message=FALSE, warning=FALSE}
colSums(is.na(accidentData))
```

Podem veure com no hi ha cap atribut amb almenys un valor nul.

Un cop comprovat que no tenim cap valor nul, cal veure si exsiteixen camps buits.

```{r echo=TRUE, message=FALSE, warning=FALSE}
colSums(accidentData=="")
```

En aquest resultat, si que podem veure com el camp TWAY_ID2 té **26997** camps buits. Aquest camp fa referència a la via de trànsit l'any 2004, per lo que es una dimensió geogràfica. Els valors en blanc poden generar problemes en el funcionament de cert algorismes durant l'etapa de construcció del model. Des del punt de vista de la gestió de característiques, cal comprovar el percentatge de valors en blanc, i així decidir què fem amb aquest camp.

```{r echo=TRUE, message=FALSE, warning=FALSE}
sum(accidentData$TWAY_ID2=="")/35766*100
```

Observem que el percentatge de valors en blanc és d'aproximadament el 75%. Si aquesta dimensió resultés d'interés, caldria plantejar-se si realment es vol tenir en compte donat l'alta proporció de dades buides. Tal com hem indicat a l'etapa d'exploració de les dades, aquesta dimensió no forma part del subconjunt d'interés, pel que serà eliminada juntament amb la resta de dades prescindibles.

### Reducció de la dimensionalitat

A continuació, prescindirem de les dimensions que no ens interessen.

```{r echo=TRUE, message=FALSE, warning=FALSE}
if (!require('ggplot2')) install.packages('ggplot2'); library('ggplot2')
if(!require('Rmisc')) install.packages('Rmisc'); library('Rmisc')
if(!require('dplyr')) install.packages('dplyr'); library('dplyr')
if(!require('xfun')) install.packages('xfun'); library('xfun')
```

```{r}
n = c("FATALS","DRUNK_DR","VE_TOTAL","VE_FORMS","PVH_INVL","PEDS","PERSONS","PERMVIT","PERNOTMVIT","STATE","MONTH","HOUR","HOURNAME","WEATHER","RELJCT2","WEATHERNAME","MONTHNAME")
accidentDataReduced = accidentData %>% select(all_of(n))
```

Aquesta reducció del nombre de dimensions permetrà millorar l'eficiència a l'hora de seguir fent el preprocessament i en una posterior construcció del model desitjat.

### Visualització de les característiques

En aquest apartat, descriurem i visualitzarem informació que ens ajudarà a entendre les dades i començar a adquirir coneixement. Primer veurem un primer resum de les dades.

```{r}
summary(accidentDataReduced)
```

D'aquest primer resum, ja podem extreure coneixement molt valiós. Per exemple, veiem com a tots els accidents hi ha com a mínim una víctima mortal. També, llegim que la mitjana és de 0.26 conductors beguts per accident.

#### Histogrames

Pot resultar interessant veure les dades mitjançant histogrames i fer algunes **obervacions**. Començarem amb el nombre de morts i de vehicles implicats.

```{r echo=TRUE, message=FALSE, warning=FALSE}
histList<- list()

n = c("FATALS","VE_TOTAL")
accidentDataAux= accidentDataReduced %>% select(all_of(n))
for(i in 1:ncol(accidentDataAux)){
  col <- names(accidentDataAux)[i]
  ggp <- ggplot(accidentDataAux, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "cornflowerblue", color = "black",ggtittle = "Comptador") 
      histList[[i]] <- ggp
}
 multiplot(plotlist = histList, cols = 1)
```

**FATALS**
Totes les tuples tenen una víctima mortal i el màxim son 8. 

**VE_TOTAL**
El mínim de vehicles implicats es 1 i el màxim 15. A la majoria gran d'accidents hi ha un o dos vechicles implicats.

```{r echo=TRUE, message=FALSE, warning=FALSE}
histList<- list()

n = c("STATE","MONTH")
accidentDataAux= accidentDataReduced %>% select(all_of(n))
for(i in 1:ncol(accidentDataAux)){
  col <- names(accidentDataAux)[i]
  ggp <- ggplot(accidentDataAux, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "cornflowerblue", color = "black",ggtittle = "Comptador") 
      histList[[i]] <- ggp
}
 multiplot(plotlist = histList, cols = 1)
```

**STATE**

Observem com hi ha molta diferencia en el nombre d'accidents per estat, molt probablement conseqüència de la quantitat de gent que viu a cada estat.

**MONTH**

Només cal fer una primera ullada al gràfic per veure que hi ha una major quantitat d'accidents durants els mesos a l'interval [5 (Maig), 12(Desembre)]. 

Com podiem imaginar, hi ha accidents a tots els estats durant tots els mesos de l'any.

```{r echo=TRUE, message=FALSE, warning=FALSE}
histList<- list()

n = c("HOUR","DRUNK_DR")
accidentDataAux= accidentDataReduced %>% select(all_of(n))
for(i in 1:ncol(accidentDataAux)){
  col <- names(accidentDataAux)[i]
  ggp <- ggplot(accidentDataAux, aes_string(x = col)) +
    geom_histogram(bins = 30, fill = "cornflowerblue", color = "black",ggtittle = "Comptador") 
      histList[[i]] <- ggp
}
 multiplot(plotlist = histList, cols = 1)
```


**HOUR**
Veiem com augmenta el nombre d'accidents a mesura que passa el dia. Veiem com hi ha hores molt elevades. Això es degut a que es va decidir afegir un 99 a tots els casos o no es savia l'hora de l'accident.

**DRUNK_DR**
El nombre de conductors beguts va de 1 a 4.

#### Relacions entre variables

Ara aprofundirem en la relació entre els conductors beguts i la condició climàtica. La hipòtesi és que pot haber més accidents provocats per persones begudes en dies més foscos, ennubolats o plujosos.

```{r echo=TRUE, message=FALSE, warning=FALSE}
files=dim(accidentDataReduced)[1]
ggplot(data=accidentDataReduced[1:files,],aes(x=DRUNK_DR,fill=WEATHERNAME))+geom_bar()+ggtitle("Relació entre les variables conductor begut i la condició climàtica")+labs(x="Nombre de conductors beguts implicats",y="Condició climàtica")
```

Aquest gràfic mostra algunes obvietats, com que la majoria d'accidents es produeixen en dies de cel clar. No es poden extreure gaires conclusions, però seria interessant veure la proporció de dies amb cel clar durant l'any, per veure si és més alta o més baixa que la que mostra el gràfic.

A continuació mostrarem les correlacions en funció de les morts i dimensions que ens poden ajudar a adquirir coneixement de les condicions que provoquen víctimes mortals:

```{r echo=TRUE, message=FALSE, warning=FALSE}
if(!require('Rmisc')) install.packages('Rmisc'); library('Rmisc')

n = c("DRUNK_DR","WEATHER","VE_TOTAL","PERSONS","PEDS") 
accidentDataAux= accidentDataReduced %>% select(all_of(n))
histList2<- vector('list', ncol(accidentDataAux))
for(i in seq_along(accidentDataAux)){
  message(i)
histList2[[i]]<-local({
  i<-i
  col <-log(accidentDataAux[[i]])
  ggp<- ggplot(data = accidentDataAux, aes(x = accidentDataReduced$FATALS, y=col)) + 
    geom_point(color = "gray30") + geom_smooth(method = lm,color = "firebrick") + 
    theme_bw() + xlab("Morts") + ylab(names(accidentDataAux)[i])
  })

}
multiplot(plotlist = histList2, cols = 3)
```

**Observacions**

+ Veiem com amb totes les variables, menys la de condició climàtica (WEATHER), augmenta el numero de morts a mesura que ho fa la variable.

+ La variable de WEATHER, al ser codis de condicions climàtiques, no mostra relació amb la quantitat de víctimes mortals.Ç


Farem el mateix amb els conductors beguts

```{r echo=TRUE, message=FALSE, warning=FALSE}
if(!require('Rmisc')) install.packages('Rmisc'); library('Rmisc')

n = c("WEATHER","VE_TOTAL","PERSONS","PEDS") 
accidentDataAux= accidentDataReduced %>% select(all_of(n))
histList2<- vector('list', ncol(accidentDataAux))
for(i in seq_along(accidentDataAux)){
  message(i)
histList2[[i]]<-local({
  i<-i
  col <-log(accidentDataAux[[i]])
  ggp<- ggplot(data = accidentDataAux, aes(x = accidentDataReduced$FATALS, y=col)) + 
    geom_point(color = "gray30") + geom_smooth(method = lm,color = "firebrick") + 
    theme_bw() + xlab("Morts") + ylab(names(accidentDataAux)[i])
  })

}
multiplot(plotlist = histList2, cols = 3)
```

Utilitzem les columnes que ens interessa per fer la matriu i la visualitzarem utilitzant la funció corrplot.

```{r echo=TRUE, message=FALSE, warning=FALSE}
if(!require("corrplot")) install.packages("corrplot"); library("corrplot")
n = c("FATALS","DRUNK_DR","VE_TOTAL","VE_FORMS","PVH_INVL","PEDS","PERSONS","PERMVIT","PERNOTMVIT","STATE","MONTH","HOUR","WEATHER")
factors= accidentDataReduced %>% select(all_of(n))
res<-cor(factors)
corrplot(res,method="color",tl.col="black", tl.srt=30, order = "AOE", 
   number.cex=0.75,sig.level = 0.01, addCoef.col = "black")
```

Observem un alt grau de correlació entre :
+ Persones que no anaven amb vehicle motoritzat (PERNOTMVIT) i Vianants implicats (PEDS)
+ Ocupants de vehicles implicats(PERSONS) i conductors i ocupants implicats(PERMIVIT)
+ Vehicles implicats en total (VE_TOTAL) i nombre de vehicles en moviment implicats(VE_FORMS)

Aprofundirem en la correlació entre persones begudes i víctimes mortals, ja que a priori sembla que estiguin menys relacionades del que es podia pensar en un principi. Utilitzarem el mètode **kendall**.

```{r echo=TRUE, message=FALSE, warning=FALSE}
if (!require('tidyverse')) install.packages('tidyverse'); library('tidyverse')
cor.test(x = accidentDataReduced$DRUNK_DR, y = accidentDataReduced$FATALS, method = "kendall")
```

Després d'observar el grau de correlació de Kendall, podem dir que el nombre de persones mortes augmenta quan el nombre de conductors beguts és més alt, pero la correlació no és d'un grau tan alt com podiem pensar en un principi. De fet, es tan baix que podria ser un grau positiu de correlació sense importància a efectes pràctics.

## Transformació de les dades
Com hem vist anteriorment, tenim alguns atributs que estan tan correlacionats que aporten la mateixa informació, com és el cas de PERNOTMVIT amb PEDS i VE_TOTAL amb VE_FORMS. En aquests casos, cal eliminar una de les dues característiques. 


```{r echo=TRUE, message=FALSE, warning=FALSE}
accidentDataReduced$PERNOTMVIT<- NULL
accidentDataReduced$VE_FORMS<- NULL

str(accidentDataReduced)
```

També modificarem els valors que prenen alguns atributs a través de la **Normalització** i la **Discretització**. 

### Discretització

Treballarem amb la característica MONTH. Assignarem un 1,2,3 o 4 depenent del trimestre. Cal tenir en compte que s'ha assignat un 99 als mesos que no es tenia informació, pel que no els tindrem en compte.

```{r}

accidentDataAux=subset(accidentDataReduced, accidentDataReduced$MONTH <= 12)

summary(accidentDataAux[,"MONTH"])


```

```{r}
accidentDataAux["trimestre"] <- cut(accidentDataAux$MONTH, breaks = c(1,3,6,9,12), labels = c("Primer","Segon","Tercer","Quart"))
```


Un cop discretitzada la característica, observem com s'agrupen els accidents en trimestres

```{r}
plot(accidentDataAux$trimestre,main="Nombre d'accidents per trimestre",xlab="Trimestre", ylab="Número d'accidents",col = "ivory")
```

### Normalització

Normalitzarem pel màxim i per diferència el nombre de vianants implicats.

```{r}
accidentDataReduced$PEDS_NM<- (accidentDataReduced$PEDS/max(accidentDataReduced[,"PEDS"]))

accidentDataReduced$PEDS_ND = (accidentDataReduced$PEDS-min(accidentDataReduced$PEDS))/(max(accidentDataReduced$PEDS)-min(accidentDataReduced$PEDS))


```

Un cop normalitzat mitjançant els dos mètodes esmentats, podem comparar els tres histogrames:

```{r}

hist(accidentDataReduced$PEDS,xlab="Vianants", col="ivory",ylab="Quantitat", main="Nombre de vianants en accident")
hist(accidentDataReduced$PEDS_NM,xlab="Vianants",ylab="Quantitat",col="ivory", main="Vianants normalitzat pel màxim")
hist(accidentDataReduced$PEDS_ND,xlab="Vianants",ylab="Quantitat", col="ivory", main="Vianants normalitzat per la diferència")
```

Ara normalitzarem totes les nostres dades per la diferència i així assegurarem el bon funcionament del model.
```{r}
# Definim la funció de normalització
 nor <-function(x) { (x -min(x))/(max(x)-min(x))}
# Guardem un nou dataset normalitzat

accidentData$type<- NULL
n = c("FATALS","DRUNK_DR","VE_TOTAL","PVH_INVL","PEDS","PERSONS","PERMVIT","MONTH")

accidentData<- accidentData %>% select(all_of(n))
accidentData_nor <- as.data.frame(lapply(accidentData, nor))

 head(accidentData_nor)
```

## Procés de PCA 

L'anàlisi de components principals (PCA) és una tècnica que ens permetrà treballar amb noves característiques anomenades components, indepenets entre si. Aquest sistema permet recullir millor la variabilitat ja que está més ben adaptat al joc de dades. A la pràctica, el que farem serà afegir al joc de dades original aquests nous components principals que recullin una variabilitat més alta.

A continuació, escalarem les dades i aplicarem l'anàlisi de components principals:

```{r}
acc_scale <- scale(accidentData_nor)
pca.acc <- prcomp(acc_scale)
summary(pca.acc)
```

Veiem com el primer i segon atribut són els que més expliquen la variabilitat del conjunt de dades, representant el 0.789 i el 0.1155 respectivament.
Amb l'histograma següent podem veure el pes de cada atribut sobre el total de dades.

```{r echo=TRUE, message=FALSE, warning=FALSE}
if (!require('factoextra')) install.packages('factoextra'); library('factoextra')
#Els valors propis corresponen a la quantitat de variació explicada per cada component principal (PC).
ev= get_eig(pca.acc)
ev
fviz_eig(pca.acc)
```

Farem servir el mètode de Kaiser per escollir les característiques. Aquest mètode es quedarà amb totes les dimensions amb variància superior a 1. 

```{r}
# Calculem les components principals
pca.acc_scale <- prcomp(acc_scale)
# Mostramos la varianza de dichas variables:
var_acc_scale <- pca.acc_scale$sdev^2
head(var_acc_scale)
```

Veient aquestes variàncies, apliquem el mètode Kàiser i ens quedem amb els components 1,2 y 3.

```{r}
var <- get_pca_var(pca.acc_scale)
var
```

Els components de get_pca_var() es poden utilitzar en el diagrama de variables de la següent manera:

+ **var$coord**: coordenades de variables per crear un diagrama de dispersió.
+ **var$cos2**: representa la qualitat de representació de les variables al mapa de factors. Es calcula com les coordenades al quadrat: var.cos2 = var.coord * var.coord.
+ **var$contrib**: conté les contribucions (en percentatge) de les variables als components principals. La contribució d'una variable (var) a un determinat component principal és (en percentatge): (var.cos2 * 100) / (cos2 total del component).

```{r}
#Utilitzem els 3 components principals trobats abans
head(var$coord[,1:3],11)
```


### Qualitat de representació
A continuació, observarem la qualitat de representació de les variables en el mapa de factors.

```{r}
head(var$cos2[,1:3],11)
```
```{r}
corrplot(var$cos2[,1:3], is.corr=FALSE)
```

A continuació veurem un diagrama de barres
```{r}
fviz_cos2(pca.acc_scale, choice = "var", axes = 1:2)
```

```{r}
fviz_pca_var(pca.acc_scale,
             col.var = "cos2", 
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07"),
             repel = TRUE     
             )
```

Conclusions:

Podem observar com la variable MONTH es troba al centre de la trama, pel que no es representativa del mapa de factors. D'altra banda, atributs com PERSONS, PERMVIT O VE_TOTAL es troben molt a prop del cercle de correlacions.

### Contribució

A continuació, observem la contribució (expresada en %) de cadascuna de les característiques als components principals. Aquelles que no contribueixin a la variablitat de les primeres dimensions es podran eliminar per simplificar l'anàlisi global.

```{r}
head(var$contrib[,1:3],11)
```

```{r}
corrplot(var$contrib[,1:3], is.corr=FALSE)
``` 

```{r}
fviz_pca_var(pca.acc_scale, col.var = "contrib",
             gradient.cols = c("#00AFBB", "#E7B800", "#FC4E07")
             )
``` 

La primera observació que es pot fer i que es veu a simple vista, és que MONTH no contribueix a cap dels components principals.

D'altra banda, cal tenir en compte que totes aquelles variables que apunten cap al mateix costat, estan correlacionades de forma positiva, y sino, negativa.

Un exemple de **correlació positiva** son el vehicles totals (VE_TOTALS) i el nombre de víctimes mortals (FATALS). D'aqui podem extreure la informació que quants més vehicles implicats en l'accident, més persones poden morir.

Un exemple de correlació negativa és el nombre de vianants (PEDS) i el nombre de conductors beguts (DRUNK_DR). No sembla que hi hagi una relació de causalitat entre aquestes dues variables, pel que aquesta correlació negativa cal prendre-la com una relació estadística. 

Les variables que més contribueixen als components principals són *PERMVIT* i *PERSONS*, ademés d'estar molt correlacionades com ja indicaba la matriu de correlacions. També ho fa el nombre de vehicles totals (**VE_TOTAL**), tot i que aquesta contribueix més a la dimensió 1 que les dues anteriors.


Aquesta nova dimensió aconseguida mitjançant el PCA es podria utilitzar com a index de perillositat d'un accident. 

## Interpretació dels resultats

Hem estudiat un conjunt de dades sobre accidents de trànsit, extret del departament de transport dels Estats Units durant l'any 2020. Aquestes dades conten informacions com el nombre de víctimes mortals, conductors beguts, vehicles implicats, vianants, dates, condicions climàtiques, dimensions geogràfiques, i així fins a 81 dimensions. En total, en aquestes dades hi ha enregistrats 35766 accidents mortals.

En el procés de neteja hem vist com en general eren unes dades bastant completes, amb excepcions com ha sigut el cas del camp TWAY_ID2. A l'inici s'ha establert que aquest no era un dels camps d'interès, i per això era una dada prescindible. Hem aprofitat per reduir la dimensionalitat del conjunt de dades amb el que estàvem treballat, i hem dut a terme tota l'activitat amb el subconjunt de característiques que hem indicat que ens interessaven a l'inici.

Durant la visualització de les dades que disposàvem, hem vist com tots els accidents tenien com a mínim una víctima mortal. Altres observacions interessants són les diferències quant a nombre d'accidents entre estats, molt probablement provocades per les diferències demogràfiques entre aquests i que la majoria d'accidents s'han produït als dos últims trimestres de l'any. Aquesta última observació s'ha dut a terme discretitzant els mesos en trimestres i eliminant aquelles tuples en les quals no es tenia coneixement del mes.

Hem intentat aprofundir en la relació entre conductors beguts i condició climàtica, pensnt que podien estar relacionades d'alguna forma. No hem pogut extraure gaire informació dels gràfics que hem generat.

També hem aprofundit en la relació del nombre de víctimes mortals amb altres característiques. Hem vist que estava molt relacionat amb el nombre de vianants, de vehicles totals, i de persones dins dels cotxes. També tenia relació amb el nombre de conductors beguts, però en un grau molt més baix.

En últim lloc, hem generat una nova dimensió mitjançant la tècnica del PCA que podria ajudar-nos a valorar l'índex de perillositat i de risc de mortalitat en un accident de trànsit.
